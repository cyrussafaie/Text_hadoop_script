
-- Exercise 01
-- Reading from text file.  Result is overall aggregation
-- Load flat file 'medicare'
medicare = LOAD '/user/kadochnikov/Medicare_DB/Medicare-Physician-and-Other-Supplier-PUF-CY2012.txt' AS 
(npi: CHARARRAY,
nppes_provider_last_org_name: CHARARRAY,
nppes_provider_first_name: CHARARRAY,
nppes_provider_mi: CHARARRAY,
nppes_credentials: CHARARRAY,
nppes_provider_gender: CHARARRAY,
nppes_entity_code: CHARARRAY,
nppes_provider_street1: CHARARRAY,
nppes_provider_street2: CHARARRAY,
nppes_provider_city: CHARARRAY,
nppes_provider_zip: CHARARRAY,
nppes_provider_state: CHARARRAY,
nppes_provider_country: CHARARRAY,
provider_type: CHARARRAY,
medicare_participation_indicator: CHARARRAY,
place_of_service: CHARARRAY,
hcpcs_code: CHARARRAY,
hcpcs_description: CHARARRAY,
line_srvc_cnt: FLOAT,
bene_unique_cnt: FLOAT,
bene_day_srvc_cnt: FLOAT,
average_medicare_allowed_amt: FLOAT,
stdev_medicare_allowed_amt: FLOAT,
average_submitted_chrg_amt: FLOAT,
stdev_submitted_chrg_amt: FLOAT,
average_medicare_payment_amt: FLOAT,
stdev_medicare_payment_amt: FLOAT);

-- Compute the average charges and payments of the table
charges = GROUP medicare ALL;
out = FOREACH charges GENERATE 
	AVG(medicare.average_submitted_chrg_amt), 
	AVG(medicare.average_medicare_payment_amt);
DUMP out;



-- Exercise 02
-- In the pig editor in hue go to Properties -> Resources -> and add an entry with Type=File and Value=/user/hive/hive-site.xml
-- Reading from Hive.  Result are aggregate over entire table?
-- Load table 'medicare'
medicare = LOAD 'medicare' USING org.apache.hive.hcatalog.pig.HCatLoader();

-- Compute the average charges and payments of the table
charges = GROUP medicare ALL;
out = FOREACH charges GENERATE 
	AVG(medicare.average_submitted_chrg_amt), 
	AVG(medicare.average_medicare_payment_amt);
DUMP out;



-- Exercise 03
-- Reading from Hive.  Result is by provider_type... but where is provider_type?
-- Load table 'medicare'
medicare = LOAD 'medicare' USING org.apache.hive.hcatalog.pig.HCatLoader();

-- Compute the average charges and payments of the table
charges = GROUP medicare BY provider_type;
out = FOREACH charges GENERATE 
	AVG(medicare.average_submitted_chrg_amt), 
	AVG(medicare.average_medicare_payment_amt);
DUMP out;






-- Exercise 04
-- Reading from Hive.  Result is by provider_type.
-- Adding a provider type to #03

medicare = LOAD 'medicare' USING org.apache.hive.hcatalog.pig.HCatLoader();

charges = GROUP medicare BY provider_type;
out = FOREACH charges GENERATE 
	group as provider_type,
	AVG(medicare.average_submitted_chrg_amt) as average_submitted_chrg_amt, 
	AVG(medicare.average_medicare_payment_amt) as average_medicare_payment_amt;
DUMP out;







-- Exercise 05.  
-- Same as #04, but now writing to a file

medicare = LOAD 'medicare' USING org.apache.hive.hcatalog.pig.HCatLoader();

charges = GROUP medicare BY provider_type;

out = FOREACH charges GENERATE 
	group as provider_type,
	AVG(medicare.average_submitted_chrg_amt) as average_submitted_chrg_amt, 
	AVG(medicare.average_medicare_payment_amt) as average_medicare_payment_amt;

-- Removing existing directory
rmf /user/kadochnikov/Medicare_DB_Sum
STORE out INTO '/user/kadochnikov/Medicare_DB_Sum';
--Note how many "parts" - number of reducers!











-- Exercise 06.  
--Forcing a single output.  Is this a good practice?
medicare = LOAD 'medicare' USING org.apache.hive.hcatalog.pig.HCatLoader();

charges = GROUP medicare BY provider_type;

out = FOREACH charges GENERATE 
	group as provider_type,
	AVG(medicare.average_submitted_chrg_amt) as average_submitted_chrg_amt, 
	AVG(medicare.average_medicare_payment_amt) as average_medicare_payment_amt;

rmf /user/kadochnikov/Medicare_DB_Sum

--forcing a single file output.  
reduced = FOREACH (GROUP out BY RANDOM()) GENERATE FLATTEN(out);
STORE reduced INTO '/user/kadochnikov/Medicare_DB_Sum';
-- In reality, most applications on Hadoop will take a directory as an input and read all the files contained in it.







-- Exercise 07. 
-- Now saving output into Hive table
SET hcat.bin /usr/bin/hcat;
medicare = LOAD 'medicare' USING org.apache.hive.hcatalog.pig.HCatLoader();

charges = GROUP medicare BY provider_type;

out = FOREACH charges GENERATE 
	group as provider_type,
	AVG(medicare.average_submitted_chrg_amt) as average_submitted_chrg_amt, 
	AVG(medicare.average_medicare_payment_amt) as average_medicare_payment_amt;
	
sql drop table medicare_s1;
sql create table medicare_s1 (provider_type string, average_submitted_chrg_amt double, average_medicare_payment_amt double); 

STORE out INTO 'medicare_s1' USING org.apache.hive.hcatalog.pig.HCatStorer();






-- Exercise 08. 
-- I want to add a "place_of_service" variable to the query
SET hcat.bin /usr/bin/hcat;

A = LOAD 'medicare' USING org.apache.hive.hcatalog.pig.HCatLoader();

B = FILTER A BY place_of_service in ('F', 'O');

C = GROUP B BY (place_of_service, provider_type);

D = FOREACH C GENERATE 
	FLATTEN(group) as (place_of_service, provider_type), 
	COUNT(B) as records,
	AVG(B.average_submitted_chrg_amt) as average_submitted_chrg, 
	SUM(B.average_submitted_chrg_amt) as tot_submitted_chrg,
	AVG(B.average_medicare_payment_amt) as average_medicare_payment,
	SUM(B.average_medicare_payment_amt) as tot_medicare_payment;
	

	
sql drop table medicare_s2;
sql create table medicare_s2 (place_of_service string, provider_type string, 
	records bigint, 
	average_submitted_chrg double, 
	tot_submitted_chrg double, 
	average_medicare_payment double, 
	tot_medicare_payment double);

STORE D INTO 'medicare_s2' USING org.apache.hive.hcatalog.pig.HCatStorer();







-- Exercise 09.
SET hcat.bin /usr/bin/hcat;
REGISTER /opt/cloudera/parcels/CDH/lib/pig/piggybank.jar

sql drop table lungcap;
sql create table lungcap (lungcap float, age int, height float, smoke string, gender string, caesarean string);


A = LOAD '/user/kadochnikov/Data/LungCapData.txt' USING org.apache.pig.piggybank.storage.CSVExcelStorage(',', 'NO_MULTILINE', 'UNIX', 'SKIP_INPUT_HEADER')
as (lungcap: float, age: int, height: float, smoke: chararray, gender: chararray, caesarean: chararray);

STORE A INTO 'lungcap' USING org.apache.hive.hcatalog.pig.HCatStorer();


F = LOAD 'lungcap' USING org.apache.hive.hcatalog.pig.HCatLoader();
G = limit F 10;
dump G;



-- Describe helps you understand how the data is stored internally in Pig
describe D;

-- Helps you understand how to convert data types from Pig to Hive
https://cwiki.apache.org/confluence/display/Hive/HCatalog+LoadStore#HCatalogLoadStore-TypesinHive0.13.0andLater.1

